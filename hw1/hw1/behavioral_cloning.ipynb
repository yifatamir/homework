{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS294-112 Deep Reinforcement Learning HW1 Q3 Behavioral Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yifat Amir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tf_util\n",
    "import gym\n",
    "import sklearn.utils as sku\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_splits(obs_file, act_file, train_amount = None):\n",
    "    print('loading expert observations and actions data')\n",
    "\n",
    "    obs = np.load(obs_file).astype(np.float32)\n",
    "    scaler = StandardScaler().fit(obs)\n",
    "    obs = scaler.transform(obs).astype(np.float32)\n",
    "    \n",
    "    act = np.squeeze(np.load(act_file).astype(np.float32))\n",
    "    \n",
    "    if train_amount == None:\n",
    "        return obs, None, act, None, scaler\n",
    "    n_samples = obs.shape[0]\n",
    "    obs_train, obs_test = train_test_split(obs, train_size = train_amount)\n",
    "    act_train, act_test = train_test_split(act, train_size = train_amount)\n",
    "    return obs_train, obs_test, act_train, act_test, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs_file, act_file = (\"obs_Ant-v1112809102017.npy\", \"act_Ant-v1112809102017.npy\")\n",
    "# (\"obs_Hopper-v1044909042017.npy\", \"act_Hopper-v1044909042017.npy\")\n",
    "# (\"obs_Humanoid-v1044209042017.npy\", \"act_Humanoid-v1044209042017.npy\")\n",
    "# (\"obs_Ant-v1112809102017.npy\", \"act_Ant-v1112809102017.npy\")\n",
    "# (\"obs_Reacher-v1113609102017.npy\", \"act_Reacher-v1113609102017.npy\")\n",
    "# (\"obs_HalfCheetah-v1114209102017.npy\", \"act_HalfCheetah-v1114209102017.npy\")\n",
    "# (\"obs_Walker2d-v1115109102017.npy\", \"act_Walker2d-v1115109102017.npy\")\n",
    "creature = \"Ant\"\n",
    "num_iters = 20000\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train My Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading expert observations and actions data\n",
      "(20000, 111)\n",
      "(20000, 8)\n",
      "iter # 0\n",
      "iter # 2000\n",
      "iter # 4000\n",
      "iter # 6000\n",
      "iter # 8000\n",
      "iter # 10000\n",
      "iter # 12000\n",
      "iter # 14000\n",
      "iter # 16000\n",
      "iter # 18000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "obs_train, obs_test, act_train, act_test, scaler = get_train_test_splits(obs_file, act_file)\n",
    "print obs_train.shape\n",
    "print act_train.shape\n",
    "num_obs_features = obs_train.shape[1]\n",
    "num_act_features = act_train.shape[1]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, num_obs_features])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, num_act_features])\n",
    "\n",
    "layer1 = tf.contrib.layers.fully_connected(x, num_obs_features, activation_fn = tf.nn.tanh, weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer2 = tf.contrib.layers.fully_connected(layer1, num_obs_features, activation_fn = tf.nn.tanh, weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "y = tf.contrib.layers.fully_connected(layer2, num_act_features, activation_fn = None, weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "policy_fn = tf_util.function([x], y)\n",
    "\n",
    "loss = tf.nn.l2_loss(y_ - y) / batch_size\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "tf.global_variables_initializer().run()\n",
    "losses = []\n",
    "for i in range(num_iters):\n",
    "    x_batch, y_batch = sku.shuffle(obs_train, act_train, n_samples = batch_size)\n",
    "    a, loss_now = sess.run(fetches=[train_step, loss], feed_dict={x: x_batch, y_: y_batch})\n",
    "    if (i % (num_iters/10) == 0):\n",
    "        print \"iter #\", i\n",
    "        losses.append(loss_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5730798, 0.0041882098, 0.0021985422, 0.0022251981, 0.0017148277, 0.0018956367, 0.0014221952, 0.0012696092, 0.0014165604, 0.0014482593]\n"
     ]
    }
   ],
   "source": [
    "print losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# print sess.run(accuracy, feed_dict={x: obs_test, y_: act_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run My Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-10 23:40:06,247] Making new env: Ant-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('returns', [4828.8983074055695, 4831.0657919480209, 4871.5881312383444, 4690.9101505301323, 5021.2595768729643, 4928.2746530856039, 4880.8356549256059, 4812.5590721329954, 4754.5010128405293, 4637.6080232776903, 4770.1393127355605, 4861.814041478503, 4828.4675562487946, 4758.5004617430013, 4855.9849644054375, 4758.8032705891728, 4731.8348826969859, 4911.3045144043472, 4776.8819480952661, 5009.3720312597798])\n",
      "('mean return', 4826.0301678957157)\n",
      "('std of return', 94.683920861485731)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(creature + \"-v1\")\n",
    "max_steps = env.spec.timestep_limit\n",
    "\n",
    "returns = []\n",
    "observations = []\n",
    "actions = []\n",
    "for i in range(20):\n",
    "#     print('iter', i)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    totalr = 0.\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        action = policy_fn(scaler.transform(obs[None,:]).astype('float32'))\n",
    "        observations.append(obs)\n",
    "        actions.append(action)\n",
    "        obs, r, done, _ = env.step(action)\n",
    "        totalr += r\n",
    "        steps += 1\n",
    "#         env.render()\n",
    "#         if steps % 100 == 0: print(\"%i/%i\"%(steps, max_steps))\n",
    "        if steps >= max_steps:\n",
    "            break\n",
    "    returns.append(totalr)\n",
    "\n",
    "print('returns', returns)\n",
    "print('mean return', np.mean(returns))\n",
    "print('std of return', np.std(returns))\n",
    "\n",
    "my_data = {'observations': np.array(observations),\n",
    "               'actions': np.array(actions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Task</td><td>My Mean of Returns</td><td>My SD of Returns</td><td>Expert Mean of Returns</td><td>Expert SD of Returns</td></tr><tr><td>Ant</td><td>4852.50172309</td><td>74.2398030029</td><td>4782.16091724</td><td>132.555603119</td></tr><tr><td>Walker2d</td><td>4995.4266902</td><td>1242.65553931</td><td>5534.92655192</td><td>44.5002486121</td></tr><tr><td>Hopper</td><td>1722.43819117</td><td>1216.78097727</td><td>3777.9972139</td><td>3.20571253539</td></tr><tr><td>Reacher</td><td>-4.86192835166</td><td>1.69605609577</td><td>-3.89877452701</td><td>1.81825232762</td></tr><tr><td>Humanoid</td><td>10385.5954084</td><td>52.9418006081</td><td>10411.3670062</td><td>64.3865538357</td></tr><tr><td>HalfCheetah</td><td>4049.21748582</td><td>92.0304040342</td><td>4158.39699685</td><td>46.9716858278</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [[\"Task\", \"My Mean of Returns\", \"My SD of Returns\", \"Expert Mean of Returns\", \"Expert SD of Returns\"],\n",
    "         [\"Ant\", 4852.5017230854846, 74.23980300289098, 4782.1609172421513, 132.55560311907271],\n",
    "         [\"Walker2d\", 4995.4266902009167, 1242.6555393075696, 5534.9265519203136, 44.500248612112557],\n",
    "         [\"Hopper\", 1722.4381911703872, 1216.7809772698199, 3777.9972139025776, 3.2057125353927498],\n",
    "         [\"Reacher\", -4.8619283516599729, 1.6960560957721855, -3.8987745270062617, 1.8182523276231009],\n",
    "         [\"Humanoid\", 10385.595408411633, 52.941800608114725, 10411.367006191223, 64.386553835708511],\n",
    "         [\"HalfCheetah\", 4049.217485821292, 92.03040403417107, 4158.3969968545998, 46.971685827755344],\n",
    "         ]\n",
    "\n",
    "display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format('</tr><tr>'.join('<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in data))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tasks were run on a NN with two hidden layers, tanh activation, 20000 sample points, 20000 training iterations, batch size of 100, and learning rate of 0.001. Most tasks achieve comparable performance, except Hopper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading expert observations and actions data\n",
      "training with learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-10 23:47:42,828] Making new env: Ant-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-10 23:49:12,298] Making new env: Ant-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-10 23:50:35,083] Making new env: Ant-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with learning rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-10 23:52:00,258] Making new env: Ant-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with learning rate: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-10 23:53:28,583] Making new env: Ant-v1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEUCAYAAADuqdsBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIiIiIiIiIiIiIgLA/wcDRO1+LMpFCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110616410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_returns = []\n",
    "obs_train, obs_test, act_train, act_test, scaler = get_train_test_splits(obs_file, act_file)\n",
    "num_obs_features = obs_train.shape[1]\n",
    "num_act_features = act_train.shape[1]\n",
    "\n",
    "lr_list = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "for learning_rate in lr_list:\n",
    "    print \"training with learning rate:\", learning_rate\n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, num_obs_features])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, num_act_features])\n",
    "\n",
    "    layer1 = tf.contrib.layers.fully_connected(x, num_obs_features, activation_fn = tf.nn.tanh, weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    layer2 = tf.contrib.layers.fully_connected(layer1, num_obs_features, activation_fn = tf.nn.tanh, weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    y = tf.contrib.layers.fully_connected(layer2, num_act_features, activation_fn = None, weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    policy_fn = tf_util.function([x], y)\n",
    "\n",
    "    loss = tf.nn.l2_loss(y_ - y) / batch_size\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(num_iters):\n",
    "        x_batch, y_batch = sku.shuffle(obs_train, act_train, n_samples = batch_size)\n",
    "        a, loss_now = sess.run(fetches=[train_step, loss], feed_dict={x: x_batch, y_: y_batch})\n",
    "            \n",
    "    env = gym.make(creature + \"-v1\")\n",
    "    max_steps = env.spec.timestep_limit\n",
    "\n",
    "    returns = []\n",
    "    observations = []\n",
    "    actions = []\n",
    "    for i in range(20):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        totalr = 0.\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            action = policy_fn(scaler.transform(obs[None,:]).astype('float32'))\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            totalr += r\n",
    "            steps += 1\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "        returns.append(totalr)\n",
    "\n",
    "    mean_returns.append(np.mean(returns))\n",
    "    \n",
    "    sess.close()\n",
    "\n",
    "plt.plot(lr_list, mean_returns)\n",
    "plt.ylabel('Mean Return')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ant\n"
     ]
    }
   ],
   "source": [
    "print creature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above shows how performance varies with the value of the learning rate. I chose to experiment with this hyperparameter because it can greatly affect the optimization of the loss function. If the learning rate is too high, it is easy to overshoot a local optimum in the cost function. If the learning rate is too low, then it is hard to learn anything given a fixed number of training iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix of Expert Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopper expert returns: \n",
    "\n",
    "('returns', [3771.9336598726591, 3774.6625045070514, 3779.9935082891625, 3771.5253685435282, 3777.3681930911616, 3778.839472656417, 3778.72690636986, 3780.420514438782, 3778.5508451495007, 3777.3928509435241, 3780.6255379793006, 3775.5027294050469, 3776.7569006634217, 3780.9128980517853, 3782.9810844516765, 3773.5071795005179, 3782.8216694611729, 3778.8721318571479, 3781.2896818439012, 3777.2606409759246])\n",
    "\n",
    "\n",
    "('mean return', 3777.9972139025776)\n",
    "('std of return', 3.2057125353927498)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humanoid expert returns:\n",
    "\n",
    "('returns', [10426.901581297876, 10354.999386314665, 10518.526981022384, 10362.961354650473, 10397.952862427941, 10446.38337188637, 10430.008532411424, 10393.84011458044, 10354.894427755571, 10462.98034042896, 10478.465784041504, 10294.904552806682, 10486.55218058908, 10467.231468828335, 10418.502544063733, 10508.646297411087, 10427.947459059114, 10364.952755875134, 10331.624674666315, 10299.063453707358])\n",
    "\n",
    "('mean return', 10411.367006191223)\n",
    "('std of return', 64.386553835708511)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reacher expert returns:\n",
    "\n",
    "('returns', [-4.186911948636455, -5.2678239265846116, -6.0242261321475707, -3.372837307792369, -4.1526844029394097, -4.8800377997838567, -3.7797431463669269, -1.7708528883578709, -7.7285160804080837, -1.9489484559423917, -6.678527275516446, -4.1668850712442085, -5.0495028527687227, -1.43408737401054, -0.82961070795971548, -3.5888372914308166, -1.5595323005597548, -2.5248902640517321, -5.6329022633401271, -3.3981330502836196])\n",
    "\n",
    "('mean return', -3.8987745270062617)\n",
    "('std of return', 1.8182523276231009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ant expert returns:\n",
    "\n",
    "('returns', [4634.3406190538553, 4679.9912036002106, 4953.8808445439299, 4990.3345743233913, 4890.1763907943932, 4707.2176554932867, 4829.1796412666581, 4666.6558116610486, 4849.3110733590174, 4724.8338142283865, 4740.5009526333615, 4833.1880590325636, 4682.7170248359034, 4761.0720917128101, 4462.971570585778, 4938.5729851855885, 4712.6437039011062, 4748.6394716855511, 4814.7542912273575, 5022.2365657188247])\n",
    "\n",
    "('mean return', 4782.1609172421513)\n",
    "('std of return', 132.55560311907271)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HalfCheetah expert returns:\n",
    "\n",
    "('returns', [4190.3812970932131, 4073.6968478036711, 4258.4218992211117, 4119.4144849436952, 4202.9336097251908, 4194.1485746829685, 4172.1107979342378, 4158.0410111130859, 4151.7562522970111, 4098.786746364889, 4080.2011038260184, 4191.3021620500786, 4170.7342197836688, 4146.3440854739783, 4108.9181177371765, 4201.9462925619591, 4143.5537391811922, 4198.9531821384571, 4110.7335363287693, 4195.561976831631])\n",
    "\n",
    "('mean return', 4158.3969968545998)\n",
    "('std of return', 46.971685827755344)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walker2d expert returns:\n",
    "\n",
    "('returns', [5585.2095384049071, 5460.791894766493, 5542.7623746208019, 5556.2732016421041, 5616.1747022383288, 5478.9192690510554, 5460.9133160694964, 5577.302376401778, 5527.9755056623562, 5599.083870098093, 5559.6238085367822, 5520.2790046826685, 5463.2838409422829, 5566.7195260477056, 5570.9962618069103, 5516.0585803941567, 5514.0024564038231, 5510.1747546902252, 5525.7448436481145, 5546.2419122981983])\n",
    "('mean return', 5534.9265519203136)\n",
    "('std of return', 44.500248612112557)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
